# EmgDataVR

This is the official repository for the paper “Facial EMG sensing for monitoring affect using a wearable device”. It contains the code and the dataset used for the analysis presented in the paper. The EmgDataVR dataset was created by [Emteq Labs](https://www.emteqlabs.com/).

# Description
- For data collection, we used the [emteqPRO system](https://www.emteqlabs.com/emteqpro/), consisting of a VR sensor mask insert with a Pico Neo 2 Eye VR headset.
- The data used for the analysis were collected from a group of 38 healthy volunteers (14 females and 24 males, with a mean age of 33.4 ± 13.6)
- The affective stimuli database used in the study contains a total of 25 videos. A combination of video stimuli was selected from the public video library by [Samson et al.](https://www.tandfonline.com/doi/abs/10.1080/02699931.2015.1031089?journalCode=pcem20) and from a study by Gnacek et al., and seven new videos were introduced.
- Each participant's data is stored in a separate .csv file that contains the EMG contact (impedance), EMG Filtered, and EMG Amplitude (RMS) sensor data, followed by   labels representing the type of an affective video that the participant was watching, and the participant’s arousal and valence ratings.
- The total duration of the collected data is around 8.5 hours. 

# Download
The EmgDataVR dataset and the code for replicating the data preprocessing steps and generating the statistical results presented in the paper can be downloaded at the following [link](https://drive.google.com/drive/folders/18LhP7-hisSZvuFrF8SHiFOBUdWvjuMdA?usp=sharing).

The affective stimuli database can be downloaded [here](https://drive.google.com/file/d/1Qr6N2b4kf0FW7rJNfdUYR1lF7AElET-5/view?usp=sharing).


# Contact 
For any information about the **EmgDataVR** feel free to contact us at ivana.kiprijanovska@emteqlabs.com
